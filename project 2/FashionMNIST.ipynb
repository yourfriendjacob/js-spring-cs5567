{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "hASLpyncBmvt"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "zsh:1: 2.0.0 not found\n"
          ]
        }
      ],
      "source": [
        "!pip install -U portalocker>=2.0.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3IIK5kzHGH0"
      },
      "source": [
        "## PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "_aWMlQ33ByRO"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "jOCzfnBvB_bQ"
      },
      "outputs": [],
      "source": [
        "# Transformations --> this is a \"pre-processing step\" that's typical for image processing methods\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),  # Convert PIL image or numpy.ndarray to tensor\n",
        "    transforms.Normalize((0.5,), (0.5,))  # Normalize data to range [-1, 1]\n",
        "])\n",
        "\n",
        "# This dataset is already \"sorted\" as part of the import method, but no \"validation\" set has been selected in this case\n",
        "# Loading the FashionMNIST dataset\n",
        "train_dataset = torchvision.datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = torchvision.datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "# Training and Testing loaders\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "jZk_FS9JCLOH"
      },
      "outputs": [],
      "source": [
        "# Mapping the labels for the MNIST dataset -- later we'll see that this using the \"keras to_categorical\" method as discussed in class\n",
        "labels_map = {\n",
        "    0: \"0\", 1: \"1\", 2: \"2\", 3: \"3\", 4: \"4\",\n",
        "    5: \"5\", 6: \"6\", 7: \"7\", 8: \"8\", 9: \"9\"\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "ykrRIGSdCMu5"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x800 with 9 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#This cell is designed to display a few images from the dataset\n",
        "#It isn't necessary to run this, but it can help give a better idea of the challanges your model will face\n",
        "figure = plt.figure(figsize=(8, 8))\n",
        "cols, rows = 3, 3\n",
        "\n",
        "# Displaying figures from the dataset randomly\n",
        "for i in range(1, cols * rows + 1):\n",
        "    sample_idx = torch.randint(len(train_dataset), size=(1,)).item()\n",
        "    img, label = train_dataset[sample_idx]\n",
        "    figure.add_subplot(rows, cols, i)\n",
        "    plt.title(labels_map[label])\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "3JLJ0ZFCER5m"
      },
      "outputs": [],
      "source": [
        "#Here we define the model parameters -- the general strucutre as provided here will produce a fully connected network [28x28] --> 32 --> 16 --> 10\n",
        "class MLP(nn.Module): #MLP stands for \"Multi-Layer Perceptron\"\n",
        "    def __init__(self): #this initializes the structure of the network\n",
        "        super(MLP, self).__init__()\n",
        "        self.fc1 = nn.Linear(28 * 28, 256) ## First fully connected linear layer, 28*28 input features and 32 outputs\n",
        "        self.fc2 = nn.Linear(256 , 128) ## Second fully connected linear layer, 32 inputs and 16 outputs\n",
        "        self.fc2_1 = nn.Linear(128, 64)\n",
        "        self.fc2_2 = nn.Linear(64, 32)\n",
        "        self.fc2_3 = nn.Linear(32, 16)\n",
        "        self.fc3 = nn.Linear(16, 10) ## 10 output features because MNIST has 10 target classes\n",
        "\n",
        "    def forward(self, x): #this modifies the elements of the intial structure defined above\n",
        "        x = x.view(-1, 28 * 28) #the array is sent in as a vector\n",
        "        x = torch.sigmoid(self.fc1(x)) ## Applying sigmoid activation for the first layer\n",
        "        x = torch.tanh(self.fc2(x)) ## Applying tanh activation for the second layer\n",
        "        x = torch.tanh(self.fc2_1(x))\n",
        "        x = torch.relu(self.fc2_2(x))\n",
        "        x = torch.relu(self.fc2_3(x))\n",
        "        x = self.fc3(x) ## no modifications to the activation of the output layer\n",
        "        return x\n",
        "\n",
        "# Initializing the neural network\n",
        "model = MLP()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "2hFOEXCPEVTw"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Batch 100, Loss: 1.7654364681243897\n",
            "Epoch 1, Batch 200, Loss: 1.0151229214668274\n",
            "Epoch 1, Batch 300, Loss: 0.7308707988262176\n",
            "Epoch 1, Batch 400, Loss: 0.6677068600058556\n",
            "Epoch 1, Batch 500, Loss: 0.6013151124119759\n",
            "Epoch 1, Batch 600, Loss: 0.5609830525517464\n",
            "Epoch 1, Batch 700, Loss: 0.5232785421609879\n",
            "Epoch 1, Batch 800, Loss: 0.5137086352705955\n",
            "Epoch 1, Batch 900, Loss: 0.5093313053250312\n",
            "Epoch 2, Batch 100, Loss: 0.4855357974767685\n",
            "Epoch 2, Batch 200, Loss: 0.44611777141690256\n",
            "Epoch 2, Batch 300, Loss: 0.4520362187922001\n",
            "Epoch 2, Batch 400, Loss: 0.45497595429420473\n",
            "Epoch 2, Batch 500, Loss: 0.4334766064584255\n",
            "Epoch 2, Batch 600, Loss: 0.437695799022913\n",
            "Epoch 2, Batch 700, Loss: 0.3931149333715439\n",
            "Epoch 2, Batch 800, Loss: 0.41693642020225524\n",
            "Epoch 2, Batch 900, Loss: 0.404570140838623\n",
            "Epoch 3, Batch 100, Loss: 0.39058936059474947\n",
            "Epoch 3, Batch 200, Loss: 0.3817224344611168\n",
            "Epoch 3, Batch 300, Loss: 0.3767688772082329\n",
            "Epoch 3, Batch 400, Loss: 0.3847011071443558\n",
            "Epoch 3, Batch 500, Loss: 0.377424584031105\n",
            "Epoch 3, Batch 600, Loss: 0.3750760418176651\n",
            "Epoch 3, Batch 700, Loss: 0.34190708860754965\n",
            "Epoch 3, Batch 800, Loss: 0.3819576543569565\n",
            "Epoch 3, Batch 900, Loss: 0.34845804423093796\n",
            "Epoch 4, Batch 100, Loss: 0.3543754734098911\n",
            "Epoch 4, Batch 200, Loss: 0.36940558403730395\n",
            "Epoch 4, Batch 300, Loss: 0.32960431784391403\n",
            "Epoch 4, Batch 400, Loss: 0.3432033021748066\n",
            "Epoch 4, Batch 500, Loss: 0.3315760859847069\n",
            "Epoch 4, Batch 600, Loss: 0.3416717517375946\n",
            "Epoch 4, Batch 700, Loss: 0.33252438172698023\n",
            "Epoch 4, Batch 800, Loss: 0.3206132207810879\n",
            "Epoch 4, Batch 900, Loss: 0.3590179443359375\n",
            "Epoch 5, Batch 100, Loss: 0.3254923798888922\n",
            "Epoch 5, Batch 200, Loss: 0.32906534291803835\n",
            "Epoch 5, Batch 300, Loss: 0.32499545000493524\n",
            "Epoch 5, Batch 400, Loss: 0.3022347065806389\n",
            "Epoch 5, Batch 500, Loss: 0.3278703059256077\n",
            "Epoch 5, Batch 600, Loss: 0.3086666887998581\n",
            "Epoch 5, Batch 700, Loss: 0.3236942556500435\n",
            "Epoch 5, Batch 800, Loss: 0.3176635909080505\n",
            "Epoch 5, Batch 900, Loss: 0.3250468738377094\n",
            "Epoch 6, Batch 100, Loss: 0.27299459487199784\n",
            "Epoch 6, Batch 200, Loss: 0.31327908113598824\n",
            "Epoch 6, Batch 300, Loss: 0.31549530059099196\n",
            "Epoch 6, Batch 400, Loss: 0.31041182652115823\n",
            "Epoch 6, Batch 500, Loss: 0.3103092451393604\n",
            "Epoch 6, Batch 600, Loss: 0.31029765054583547\n",
            "Epoch 6, Batch 700, Loss: 0.3021992912888527\n",
            "Epoch 6, Batch 800, Loss: 0.29111878350377085\n",
            "Epoch 6, Batch 900, Loss: 0.3099903565645218\n",
            "Epoch 7, Batch 100, Loss: 0.27516198173165324\n",
            "Epoch 7, Batch 200, Loss: 0.3039656641334295\n",
            "Epoch 7, Batch 300, Loss: 0.2824468628317118\n",
            "Epoch 7, Batch 400, Loss: 0.2701625533401966\n",
            "Epoch 7, Batch 500, Loss: 0.29982894226908685\n",
            "Epoch 7, Batch 600, Loss: 0.2894068375229836\n",
            "Epoch 7, Batch 700, Loss: 0.290142892152071\n",
            "Epoch 7, Batch 800, Loss: 0.2986891289800406\n",
            "Epoch 7, Batch 900, Loss: 0.29274508967995644\n",
            "Epoch 8, Batch 100, Loss: 0.2744777791202068\n",
            "Epoch 8, Batch 200, Loss: 0.26543044805526733\n",
            "Epoch 8, Batch 300, Loss: 0.2795892526209354\n",
            "Epoch 8, Batch 400, Loss: 0.26662535943090915\n",
            "Epoch 8, Batch 500, Loss: 0.2682267200946808\n",
            "Epoch 8, Batch 600, Loss: 0.287720407769084\n",
            "Epoch 8, Batch 700, Loss: 0.2725077307969332\n",
            "Epoch 8, Batch 800, Loss: 0.27110988199710845\n",
            "Epoch 8, Batch 900, Loss: 0.2816501522809267\n",
            "Epoch 9, Batch 100, Loss: 0.24827146090567112\n",
            "Epoch 9, Batch 200, Loss: 0.28268566146492957\n",
            "Epoch 9, Batch 300, Loss: 0.250903423205018\n",
            "Epoch 9, Batch 400, Loss: 0.26307479597628114\n",
            "Epoch 9, Batch 500, Loss: 0.2531243734806776\n",
            "Epoch 9, Batch 600, Loss: 0.27112975433468817\n",
            "Epoch 9, Batch 700, Loss: 0.26728559628129006\n",
            "Epoch 9, Batch 800, Loss: 0.26014554090797903\n",
            "Epoch 9, Batch 900, Loss: 0.26811991050839423\n",
            "Epoch 10, Batch 100, Loss: 0.2464607273042202\n",
            "Epoch 10, Batch 200, Loss: 0.25531016699969766\n",
            "Epoch 10, Batch 300, Loss: 0.24928959541022777\n",
            "Epoch 10, Batch 400, Loss: 0.24374889984726905\n",
            "Epoch 10, Batch 500, Loss: 0.25218749441206456\n",
            "Epoch 10, Batch 600, Loss: 0.24266443438827992\n",
            "Epoch 10, Batch 700, Loss: 0.24962420739233493\n",
            "Epoch 10, Batch 800, Loss: 0.24511330351233482\n",
            "Epoch 10, Batch 900, Loss: 0.26697866700589656\n",
            "Epoch 11, Batch 100, Loss: 0.22727504871785642\n",
            "Epoch 11, Batch 200, Loss: 0.2424032848700881\n",
            "Epoch 11, Batch 300, Loss: 0.2290143781155348\n",
            "Epoch 11, Batch 400, Loss: 0.24904057674109936\n",
            "Epoch 11, Batch 500, Loss: 0.24481028817594053\n",
            "Epoch 11, Batch 600, Loss: 0.25337026864290235\n",
            "Epoch 11, Batch 700, Loss: 0.23780744016170502\n",
            "Epoch 11, Batch 800, Loss: 0.2513153431564569\n",
            "Epoch 11, Batch 900, Loss: 0.26061044707894326\n",
            "Epoch 12, Batch 100, Loss: 0.2300174755603075\n",
            "Epoch 12, Batch 200, Loss: 0.22432121708989144\n",
            "Epoch 12, Batch 300, Loss: 0.22028339631855487\n",
            "Epoch 12, Batch 400, Loss: 0.24028528951108455\n",
            "Epoch 12, Batch 500, Loss: 0.228840224891901\n",
            "Epoch 12, Batch 600, Loss: 0.2386393690854311\n",
            "Epoch 12, Batch 700, Loss: 0.2524320002645254\n",
            "Epoch 12, Batch 800, Loss: 0.24101050339639188\n",
            "Epoch 12, Batch 900, Loss: 0.22691519357264042\n",
            "Epoch 13, Batch 100, Loss: 0.2249631867557764\n",
            "Epoch 13, Batch 200, Loss: 0.21869496457278728\n",
            "Epoch 13, Batch 300, Loss: 0.22436724990606308\n",
            "Epoch 13, Batch 400, Loss: 0.22553157828748227\n",
            "Epoch 13, Batch 500, Loss: 0.2371457292884588\n",
            "Epoch 13, Batch 600, Loss: 0.22591688431799412\n",
            "Epoch 13, Batch 700, Loss: 0.22446525938808917\n",
            "Epoch 13, Batch 800, Loss: 0.21861216269433498\n",
            "Epoch 13, Batch 900, Loss: 0.23321241348981858\n",
            "Epoch 14, Batch 100, Loss: 0.20430321425199507\n",
            "Epoch 14, Batch 200, Loss: 0.2032710649445653\n",
            "Epoch 14, Batch 300, Loss: 0.21931028127670288\n",
            "Epoch 14, Batch 400, Loss: 0.2339580002427101\n",
            "Epoch 14, Batch 500, Loss: 0.24084994092583656\n",
            "Epoch 14, Batch 600, Loss: 0.2233359541743994\n",
            "Epoch 14, Batch 700, Loss: 0.2117641893029213\n",
            "Epoch 14, Batch 800, Loss: 0.22079497665166856\n",
            "Epoch 14, Batch 900, Loss: 0.23149437442421913\n",
            "Epoch 15, Batch 100, Loss: 0.2034759883955121\n",
            "Epoch 15, Batch 200, Loss: 0.21929369151592254\n",
            "Epoch 15, Batch 300, Loss: 0.2065500809252262\n",
            "Epoch 15, Batch 400, Loss: 0.22555915646255018\n",
            "Epoch 15, Batch 500, Loss: 0.21270945608615877\n",
            "Epoch 15, Batch 600, Loss: 0.20724355384707452\n",
            "Epoch 15, Batch 700, Loss: 0.21536773584783078\n",
            "Epoch 15, Batch 800, Loss: 0.2092093726992607\n",
            "Epoch 15, Batch 900, Loss: 0.21328317895531654\n",
            "Epoch 16, Batch 100, Loss: 0.20401285372674466\n",
            "Epoch 16, Batch 200, Loss: 0.20922953825443982\n",
            "Epoch 16, Batch 300, Loss: 0.18964665099978448\n",
            "Epoch 16, Batch 400, Loss: 0.1952831269055605\n",
            "Epoch 16, Batch 500, Loss: 0.2023973260074854\n",
            "Epoch 16, Batch 600, Loss: 0.20294016405940055\n",
            "Epoch 16, Batch 700, Loss: 0.20308404833078383\n",
            "Epoch 16, Batch 800, Loss: 0.20589785240590572\n",
            "Epoch 16, Batch 900, Loss: 0.19337665516883135\n",
            "Epoch 17, Batch 100, Loss: 0.19060747176408768\n",
            "Epoch 17, Batch 200, Loss: 0.20627677887678147\n",
            "Epoch 17, Batch 300, Loss: 0.19907809305936097\n",
            "Epoch 17, Batch 400, Loss: 0.18493685588240624\n",
            "Epoch 17, Batch 500, Loss: 0.1997990134358406\n",
            "Epoch 17, Batch 600, Loss: 0.1963245951011777\n",
            "Epoch 17, Batch 700, Loss: 0.20111406218260527\n",
            "Epoch 17, Batch 800, Loss: 0.19699695102870465\n",
            "Epoch 17, Batch 900, Loss: 0.19767283428460358\n",
            "Epoch 18, Batch 100, Loss: 0.19291300870478154\n",
            "Epoch 18, Batch 200, Loss: 0.18173327028751374\n",
            "Epoch 18, Batch 300, Loss: 0.19046317353844644\n",
            "Epoch 18, Batch 400, Loss: 0.18513908803462983\n",
            "Epoch 18, Batch 500, Loss: 0.20926263961941005\n",
            "Epoch 18, Batch 600, Loss: 0.18523341696709394\n",
            "Epoch 18, Batch 700, Loss: 0.18179068110883237\n",
            "Epoch 18, Batch 800, Loss: 0.1939648035541177\n",
            "Epoch 18, Batch 900, Loss: 0.2020514126867056\n",
            "Epoch 19, Batch 100, Loss: 0.18183679308742284\n",
            "Epoch 19, Batch 200, Loss: 0.1883015800639987\n",
            "Epoch 19, Batch 300, Loss: 0.17621971003711223\n",
            "Epoch 19, Batch 400, Loss: 0.20825515933334826\n",
            "Epoch 19, Batch 500, Loss: 0.17668275274336337\n",
            "Epoch 19, Batch 600, Loss: 0.1840342890843749\n",
            "Epoch 19, Batch 700, Loss: 0.1751782848313451\n",
            "Epoch 19, Batch 800, Loss: 0.19215757559984922\n",
            "Epoch 19, Batch 900, Loss: 0.1967256060987711\n",
            "Epoch 20, Batch 100, Loss: 0.18482731502503158\n",
            "Epoch 20, Batch 200, Loss: 0.18539451602846385\n",
            "Epoch 20, Batch 300, Loss: 0.1965759276598692\n",
            "Epoch 20, Batch 400, Loss: 0.1733384568616748\n",
            "Epoch 20, Batch 500, Loss: 0.17952696554362774\n",
            "Epoch 20, Batch 600, Loss: 0.1811193871498108\n",
            "Epoch 20, Batch 700, Loss: 0.17618026953190566\n",
            "Epoch 20, Batch 800, Loss: 0.1862019991874695\n",
            "Epoch 20, Batch 900, Loss: 0.18504740953445434\n",
            "Epoch 21, Batch 100, Loss: 0.1636828712373972\n",
            "Epoch 21, Batch 200, Loss: 0.154255725517869\n",
            "Epoch 21, Batch 300, Loss: 0.183248279877007\n",
            "Epoch 21, Batch 400, Loss: 0.1848488388955593\n",
            "Epoch 21, Batch 500, Loss: 0.17067924425005912\n",
            "Epoch 21, Batch 600, Loss: 0.1721190509945154\n",
            "Epoch 21, Batch 700, Loss: 0.17300951156765224\n",
            "Epoch 21, Batch 800, Loss: 0.16593845803290605\n",
            "Epoch 21, Batch 900, Loss: 0.1833015175536275\n",
            "Epoch 22, Batch 100, Loss: 0.15696695666760208\n",
            "Epoch 22, Batch 200, Loss: 0.16712958756834267\n",
            "Epoch 22, Batch 300, Loss: 0.15709119938313962\n",
            "Epoch 22, Batch 400, Loss: 0.16454820070415735\n",
            "Epoch 22, Batch 500, Loss: 0.16912705540657044\n",
            "Epoch 22, Batch 600, Loss: 0.16712619494646788\n",
            "Epoch 22, Batch 700, Loss: 0.18302221838384866\n",
            "Epoch 22, Batch 800, Loss: 0.18260526310652495\n",
            "Epoch 22, Batch 900, Loss: 0.16314975388348102\n",
            "Epoch 23, Batch 100, Loss: 0.1580094142258167\n",
            "Epoch 23, Batch 200, Loss: 0.15511421710252762\n",
            "Epoch 23, Batch 300, Loss: 0.16566874992102384\n",
            "Epoch 23, Batch 400, Loss: 0.15368352806195618\n",
            "Epoch 23, Batch 500, Loss: 0.17072252102196217\n",
            "Epoch 23, Batch 600, Loss: 0.17362981393933297\n",
            "Epoch 23, Batch 700, Loss: 0.16367287166416644\n",
            "Epoch 23, Batch 800, Loss: 0.1541406638920307\n",
            "Epoch 23, Batch 900, Loss: 0.1633425721898675\n",
            "Epoch 24, Batch 100, Loss: 0.15888850934803486\n",
            "Epoch 24, Batch 200, Loss: 0.1582638893648982\n",
            "Epoch 24, Batch 300, Loss: 0.15145094152539967\n",
            "Epoch 24, Batch 400, Loss: 0.16530808106064795\n",
            "Epoch 24, Batch 500, Loss: 0.15017535066232085\n",
            "Epoch 24, Batch 600, Loss: 0.16079392462968825\n",
            "Epoch 24, Batch 700, Loss: 0.15821793884038926\n",
            "Epoch 24, Batch 800, Loss: 0.16137154135853052\n",
            "Epoch 24, Batch 900, Loss: 0.16427959110587836\n",
            "Epoch 25, Batch 100, Loss: 0.1468689875677228\n",
            "Epoch 25, Batch 200, Loss: 0.14743196845054626\n",
            "Epoch 25, Batch 300, Loss: 0.14825346499681472\n",
            "Epoch 25, Batch 400, Loss: 0.15939672684296965\n",
            "Epoch 25, Batch 500, Loss: 0.15320044860243798\n",
            "Epoch 25, Batch 600, Loss: 0.15442448489367963\n",
            "Epoch 25, Batch 700, Loss: 0.15361386615782976\n",
            "Epoch 25, Batch 800, Loss: 0.1484966768324375\n",
            "Epoch 25, Batch 900, Loss: 0.17080089431256057\n",
            "Epoch 26, Batch 100, Loss: 0.13209115732461213\n",
            "Epoch 26, Batch 200, Loss: 0.13750551087781787\n",
            "Epoch 26, Batch 300, Loss: 0.12647063203155995\n",
            "Epoch 26, Batch 400, Loss: 0.15553667100146412\n",
            "Epoch 26, Batch 500, Loss: 0.16039459010586143\n",
            "Epoch 26, Batch 600, Loss: 0.15437357723712922\n",
            "Epoch 26, Batch 700, Loss: 0.15051004506647586\n",
            "Epoch 26, Batch 800, Loss: 0.14257581710815428\n",
            "Epoch 26, Batch 900, Loss: 0.1581417715549469\n",
            "Epoch 27, Batch 100, Loss: 0.1481431855633855\n",
            "Epoch 27, Batch 200, Loss: 0.1391612602584064\n",
            "Epoch 27, Batch 300, Loss: 0.14688022285699845\n",
            "Epoch 27, Batch 400, Loss: 0.14584836922585964\n",
            "Epoch 27, Batch 500, Loss: 0.12743709687143565\n",
            "Epoch 27, Batch 600, Loss: 0.13520822074264288\n",
            "Epoch 27, Batch 700, Loss: 0.13214687656611204\n",
            "Epoch 27, Batch 800, Loss: 0.1483600166067481\n",
            "Epoch 27, Batch 900, Loss: 0.1365740231052041\n",
            "Epoch 28, Batch 100, Loss: 0.1290834929049015\n",
            "Epoch 28, Batch 200, Loss: 0.14517521614208817\n",
            "Epoch 28, Batch 300, Loss: 0.14074092691764237\n",
            "Epoch 28, Batch 400, Loss: 0.13772950364276768\n",
            "Epoch 28, Batch 500, Loss: 0.147295825406909\n",
            "Epoch 28, Batch 600, Loss: 0.13492819586768745\n",
            "Epoch 28, Batch 700, Loss: 0.14641862761229277\n",
            "Epoch 28, Batch 800, Loss: 0.14497670294716955\n",
            "Epoch 28, Batch 900, Loss: 0.15479660203680395\n",
            "Epoch 29, Batch 100, Loss: 0.13476423870772122\n",
            "Epoch 29, Batch 200, Loss: 0.12067811636254192\n",
            "Epoch 29, Batch 300, Loss: 0.1375997625105083\n",
            "Epoch 29, Batch 400, Loss: 0.13744413459673524\n",
            "Epoch 29, Batch 500, Loss: 0.13853069523349404\n",
            "Epoch 29, Batch 600, Loss: 0.1368185706436634\n",
            "Epoch 29, Batch 700, Loss: 0.12732477992773056\n",
            "Epoch 29, Batch 800, Loss: 0.12808834299445152\n",
            "Epoch 29, Batch 900, Loss: 0.13370148757472633\n",
            "Epoch 30, Batch 100, Loss: 0.14201851855963468\n",
            "Epoch 30, Batch 200, Loss: 0.12363013260066509\n",
            "Epoch 30, Batch 300, Loss: 0.130474597197026\n",
            "Epoch 30, Batch 400, Loss: 0.12414949214085937\n",
            "Epoch 30, Batch 500, Loss: 0.1355112087726593\n",
            "Epoch 30, Batch 600, Loss: 0.12534995067864657\n",
            "Epoch 30, Batch 700, Loss: 0.13848094640299677\n",
            "Epoch 30, Batch 800, Loss: 0.13076364068314433\n",
            "Epoch 30, Batch 900, Loss: 0.13484888566657902\n",
            "Epoch 31, Batch 100, Loss: 0.12279914052225649\n",
            "Epoch 31, Batch 200, Loss: 0.13757770221680402\n",
            "Epoch 31, Batch 300, Loss: 0.1196286323852837\n",
            "Epoch 31, Batch 400, Loss: 0.1342543963342905\n",
            "Epoch 31, Batch 500, Loss: 0.133794872649014\n",
            "Epoch 31, Batch 600, Loss: 0.13355479516088964\n",
            "Epoch 31, Batch 700, Loss: 0.12891064696013926\n",
            "Epoch 31, Batch 800, Loss: 0.12119057273492218\n",
            "Epoch 31, Batch 900, Loss: 0.13091280844062567\n",
            "Epoch 32, Batch 100, Loss: 0.1225926498323679\n",
            "Epoch 32, Batch 200, Loss: 0.11866133430972696\n",
            "Epoch 32, Batch 300, Loss: 0.1223028820194304\n",
            "Epoch 32, Batch 400, Loss: 0.12290673037990928\n",
            "Epoch 32, Batch 500, Loss: 0.12289291085675359\n",
            "Epoch 32, Batch 600, Loss: 0.1314617298915982\n",
            "Epoch 32, Batch 700, Loss: 0.13295094547793268\n",
            "Epoch 32, Batch 800, Loss: 0.10926273077726364\n",
            "Epoch 32, Batch 900, Loss: 0.12662107743322848\n",
            "Epoch 33, Batch 100, Loss: 0.11145190183073282\n",
            "Epoch 33, Batch 200, Loss: 0.10537137545645237\n",
            "Epoch 33, Batch 300, Loss: 0.12345639714971185\n",
            "Epoch 33, Batch 400, Loss: 0.11436818012967706\n",
            "Epoch 33, Batch 500, Loss: 0.12240339171141386\n",
            "Epoch 33, Batch 600, Loss: 0.11759786430746316\n",
            "Epoch 33, Batch 700, Loss: 0.12443198516964912\n",
            "Epoch 33, Batch 800, Loss: 0.12045063637197018\n",
            "Epoch 33, Batch 900, Loss: 0.13221679344773293\n",
            "Epoch 34, Batch 100, Loss: 0.1003148587513715\n",
            "Epoch 34, Batch 200, Loss: 0.10664680017158389\n",
            "Epoch 34, Batch 300, Loss: 0.11877511853352189\n",
            "Epoch 34, Batch 400, Loss: 0.12704940315335989\n",
            "Epoch 34, Batch 500, Loss: 0.12755977395921947\n",
            "Epoch 34, Batch 600, Loss: 0.11671170476824046\n",
            "Epoch 34, Batch 700, Loss: 0.12444146586582065\n",
            "Epoch 34, Batch 800, Loss: 0.10783166596665979\n",
            "Epoch 34, Batch 900, Loss: 0.10943383850157261\n",
            "Epoch 35, Batch 100, Loss: 0.12221693489700555\n",
            "Epoch 35, Batch 200, Loss: 0.12662006620317698\n",
            "Epoch 35, Batch 300, Loss: 0.11157150123268365\n",
            "Epoch 35, Batch 400, Loss: 0.10229473421350121\n",
            "Epoch 35, Batch 500, Loss: 0.10769803559407592\n",
            "Epoch 35, Batch 600, Loss: 0.12194960398599505\n",
            "Epoch 35, Batch 700, Loss: 0.10278361243195831\n",
            "Epoch 35, Batch 800, Loss: 0.11656201055273413\n",
            "Epoch 35, Batch 900, Loss: 0.1294050144404173\n",
            "Epoch 36, Batch 100, Loss: 0.09329209551215172\n",
            "Epoch 36, Batch 200, Loss: 0.10546344977803529\n",
            "Epoch 36, Batch 300, Loss: 0.09888147309422493\n",
            "Epoch 36, Batch 400, Loss: 0.11202067140489817\n",
            "Epoch 36, Batch 500, Loss: 0.10875973470509052\n",
            "Epoch 36, Batch 600, Loss: 0.10274544754065573\n",
            "Epoch 36, Batch 700, Loss: 0.13155497586354614\n",
            "Epoch 36, Batch 800, Loss: 0.12287143813446164\n",
            "Epoch 36, Batch 900, Loss: 0.10740639401599765\n",
            "Epoch 37, Batch 100, Loss: 0.1013017045147717\n",
            "Epoch 37, Batch 200, Loss: 0.1130739981122315\n",
            "Epoch 37, Batch 300, Loss: 0.11781835908070207\n",
            "Epoch 37, Batch 400, Loss: 0.09507735399529338\n",
            "Epoch 37, Batch 500, Loss: 0.11572427524253726\n",
            "Epoch 37, Batch 600, Loss: 0.1072980291210115\n",
            "Epoch 37, Batch 700, Loss: 0.1221637623757124\n",
            "Epoch 37, Batch 800, Loss: 0.1134941203147173\n",
            "Epoch 37, Batch 900, Loss: 0.10710880868136882\n",
            "Epoch 38, Batch 100, Loss: 0.09834969581104815\n",
            "Epoch 38, Batch 200, Loss: 0.09623471768572926\n",
            "Epoch 38, Batch 300, Loss: 0.1021385916043073\n",
            "Epoch 38, Batch 400, Loss: 0.10517266621813177\n",
            "Epoch 38, Batch 500, Loss: 0.1036580371670425\n",
            "Epoch 38, Batch 600, Loss: 0.10828898917883635\n",
            "Epoch 38, Batch 700, Loss: 0.11467757927253842\n",
            "Epoch 38, Batch 800, Loss: 0.10122280513867736\n",
            "Epoch 38, Batch 900, Loss: 0.11226225480437278\n",
            "Epoch 39, Batch 100, Loss: 0.10047549396753311\n",
            "Epoch 39, Batch 200, Loss: 0.09294780264608563\n",
            "Epoch 39, Batch 300, Loss: 0.11008049765601755\n",
            "Epoch 39, Batch 400, Loss: 0.10182955953292548\n",
            "Epoch 39, Batch 500, Loss: 0.09615960735827685\n",
            "Epoch 39, Batch 600, Loss: 0.12768798859789968\n",
            "Epoch 39, Batch 700, Loss: 0.09594454693607986\n",
            "Epoch 39, Batch 800, Loss: 0.11151154570281506\n",
            "Epoch 39, Batch 900, Loss: 0.10132225569337606\n",
            "Epoch 40, Batch 100, Loss: 0.0869844732619822\n",
            "Epoch 40, Batch 200, Loss: 0.09410435896366835\n",
            "Epoch 40, Batch 300, Loss: 0.08240211771801115\n",
            "Epoch 40, Batch 400, Loss: 0.09004064159467816\n",
            "Epoch 40, Batch 500, Loss: 0.11745183769613504\n",
            "Epoch 40, Batch 600, Loss: 0.10070876931305975\n",
            "Epoch 40, Batch 700, Loss: 0.10707981638610363\n",
            "Epoch 40, Batch 800, Loss: 0.10662994442507624\n",
            "Epoch 40, Batch 900, Loss: 0.10467430142685771\n",
            "Epoch 41, Batch 100, Loss: 0.09924614829942584\n",
            "Epoch 41, Batch 200, Loss: 0.08513559534214438\n",
            "Epoch 41, Batch 300, Loss: 0.10018984977155924\n",
            "Epoch 41, Batch 400, Loss: 0.12329561740159989\n",
            "Epoch 41, Batch 500, Loss: 0.09937249295413494\n",
            "Epoch 41, Batch 600, Loss: 0.10968146879225969\n",
            "Epoch 41, Batch 700, Loss: 0.0938768346561119\n",
            "Epoch 41, Batch 800, Loss: 0.08638603446539492\n",
            "Epoch 41, Batch 900, Loss: 0.10472481422126294\n",
            "Epoch 42, Batch 100, Loss: 0.08019875717815012\n",
            "Epoch 42, Batch 200, Loss: 0.08234522193670273\n",
            "Epoch 42, Batch 300, Loss: 0.10243488192558288\n",
            "Epoch 42, Batch 400, Loss: 0.10009125048294663\n",
            "Epoch 42, Batch 500, Loss: 0.09246183585375548\n",
            "Epoch 42, Batch 600, Loss: 0.10421343235298991\n",
            "Epoch 42, Batch 700, Loss: 0.09824164934456349\n",
            "Epoch 42, Batch 800, Loss: 0.09344063865952194\n",
            "Epoch 42, Batch 900, Loss: 0.09705790913663805\n",
            "Epoch 43, Batch 100, Loss: 0.07256129103712737\n",
            "Epoch 43, Batch 200, Loss: 0.08305091642774641\n",
            "Epoch 43, Batch 300, Loss: 0.0858571420237422\n",
            "Epoch 43, Batch 400, Loss: 0.08203685002401472\n",
            "Epoch 43, Batch 500, Loss: 0.08752240068744868\n",
            "Epoch 43, Batch 600, Loss: 0.09478768925182521\n",
            "Epoch 43, Batch 700, Loss: 0.09933081971481443\n",
            "Epoch 43, Batch 800, Loss: 0.09988535758107901\n",
            "Epoch 43, Batch 900, Loss: 0.09852459910791367\n",
            "Epoch 44, Batch 100, Loss: 0.08574801811017096\n",
            "Epoch 44, Batch 200, Loss: 0.08498564207926393\n",
            "Epoch 44, Batch 300, Loss: 0.09655218875035644\n",
            "Epoch 44, Batch 400, Loss: 0.08317959651350976\n",
            "Epoch 44, Batch 500, Loss: 0.0901492695696652\n",
            "Epoch 44, Batch 600, Loss: 0.09828037523664535\n",
            "Epoch 44, Batch 700, Loss: 0.08884178674779833\n",
            "Epoch 44, Batch 800, Loss: 0.07969084580428898\n",
            "Epoch 44, Batch 900, Loss: 0.08747038842178881\n",
            "Epoch 45, Batch 100, Loss: 0.06469791874289513\n",
            "Epoch 45, Batch 200, Loss: 0.0771721353707835\n",
            "Epoch 45, Batch 300, Loss: 0.08322190452367068\n",
            "Epoch 45, Batch 400, Loss: 0.0899601618759334\n",
            "Epoch 45, Batch 500, Loss: 0.1082440824341029\n",
            "Epoch 45, Batch 600, Loss: 0.0978651051595807\n",
            "Epoch 45, Batch 700, Loss: 0.10156096076127141\n",
            "Epoch 45, Batch 800, Loss: 0.08817410433664918\n",
            "Epoch 45, Batch 900, Loss: 0.10121307278517634\n",
            "Epoch 46, Batch 100, Loss: 0.08372193829156459\n",
            "Epoch 46, Batch 200, Loss: 0.08085647326428443\n",
            "Epoch 46, Batch 300, Loss: 0.08194756392855197\n",
            "Epoch 46, Batch 400, Loss: 0.09256776669993996\n",
            "Epoch 46, Batch 500, Loss: 0.10865927170962095\n",
            "Epoch 46, Batch 600, Loss: 0.09633790731430053\n",
            "Epoch 46, Batch 700, Loss: 0.08632621558383108\n",
            "Epoch 46, Batch 800, Loss: 0.09304314909502864\n",
            "Epoch 46, Batch 900, Loss: 0.0898455686122179\n",
            "Epoch 47, Batch 100, Loss: 0.08040425008162856\n",
            "Epoch 47, Batch 200, Loss: 0.09043755190912633\n",
            "Epoch 47, Batch 300, Loss: 0.08852012141607701\n",
            "Epoch 47, Batch 400, Loss: 0.08390408671461046\n",
            "Epoch 47, Batch 500, Loss: 0.07559186020866036\n",
            "Epoch 47, Batch 600, Loss: 0.0967062216065824\n",
            "Epoch 47, Batch 700, Loss: 0.09582440758123995\n",
            "Epoch 47, Batch 800, Loss: 0.09632279943674803\n",
            "Epoch 47, Batch 900, Loss: 0.08740543164312839\n",
            "Epoch 48, Batch 100, Loss: 0.06649060991592705\n",
            "Epoch 48, Batch 200, Loss: 0.07512310323305428\n",
            "Epoch 48, Batch 300, Loss: 0.0730188068933785\n",
            "Epoch 48, Batch 400, Loss: 0.07681808028370142\n",
            "Epoch 48, Batch 500, Loss: 0.07036686930339783\n",
            "Epoch 48, Batch 600, Loss: 0.08398553862236441\n",
            "Epoch 48, Batch 700, Loss: 0.09651304475031793\n",
            "Epoch 48, Batch 800, Loss: 0.08504087087698281\n",
            "Epoch 48, Batch 900, Loss: 0.09898746499791741\n",
            "Epoch 49, Batch 100, Loss: 0.07796973865479231\n",
            "Epoch 49, Batch 200, Loss: 0.06606178454123438\n",
            "Epoch 49, Batch 300, Loss: 0.07786834103986622\n",
            "Epoch 49, Batch 400, Loss: 0.0633688903413713\n",
            "Epoch 49, Batch 500, Loss: 0.07026915558613837\n",
            "Epoch 49, Batch 600, Loss: 0.07967797907069325\n",
            "Epoch 49, Batch 700, Loss: 0.08578213947825133\n",
            "Epoch 49, Batch 800, Loss: 0.08002763530239462\n",
            "Epoch 49, Batch 900, Loss: 0.08446610434912145\n",
            "Epoch 50, Batch 100, Loss: 0.06708504499867558\n",
            "Epoch 50, Batch 200, Loss: 0.07443299174541608\n",
            "Epoch 50, Batch 300, Loss: 0.07745457971468568\n",
            "Epoch 50, Batch 400, Loss: 0.08681529567576945\n",
            "Epoch 50, Batch 500, Loss: 0.07684504717588425\n",
            "Epoch 50, Batch 600, Loss: 0.09056014113128186\n",
            "Epoch 50, Batch 700, Loss: 0.0966106224572286\n",
            "Epoch 50, Batch 800, Loss: 0.10448829509317875\n",
            "Epoch 50, Batch 900, Loss: 0.09439589502289891\n",
            "Finished Training\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training the neural network\n",
        "num_epochs = 50\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        inputs, labels = data\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "        if i % 100 == 99:  # print every 100 mini-batches\n",
        "            print(f'Epoch {epoch + 1}, Batch {i + 1}, Loss: {running_loss / 100}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "RNMCpk60EaXr"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy on test set: 88.24%\n"
          ]
        }
      ],
      "source": [
        "# Evaluating the model\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in test_loader:\n",
        "        images, labels = data\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy on test set: { correct / total * 100}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "J2GkmLeQEeZV"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGbCAYAAAAr/4yjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/H5lhTAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAdNklEQVR4nO3de3BU9fnH8c/mupssYICAiUKAVASj1BavaA0oEEnUTqfqoK2CFYkYjbaj0lHHVPAyaMVLsPHSFhyCN+q9KlRqqJGxWhSvhYoIKmCLQYwaSEJ2v78/mDw/liQk55BsYub9mmEGzp7nnO/ZPZvPfs+ePAScc04AAEhK6O4BAAB6DkIBAGAIBQCAIRQAAIZQAAAYQgEAYAgFAIAhFAAAhlAAABhCoQsNGzZM06dPt3+vXLlSgUBAK1eu7LYx7WvfMcbD+PHjdeSRR3bqNrvjOHqz8ePHa/z48XHd5/Tp0xUOhzt1m91xHN93vTYUFi1apEAgYH+CwaBGjhypyy+/XP/73/+6e3ievPjii/rd737XrWMIBAK6/PLLu3UMXSkajer222/X8OHDFQwGNWbMGD366KOdsu21a9faOfj111/73s6tt96qZ555plPG1FmGDRumM844o7uH0aX+9Kc/afTo0QoGgzrssMNUXl7e3UPqUr02FJrNmTNHixcv1oIFCzRu3DhVVFToxBNP1M6dO+M+llNOOUW7du3SKaec4qnuxRdf1E033dRFo4IkXX/99Zo9e7YmTZqk8vJyDR06VOeff74ee+yxA952ZWWlDj74YEnSX/7yF9/b6Ymh0Ns98MADmjFjhvLy8lReXq4TTzxRpaWlmjdvXncPrcskdfcAutqUKVN0zDHHSJJmzJihAQMGaP78+Xr22Wd13nnntVpTV1en9PT0Th9LQkKCgsFgp28XB2bLli268847VVJSogULFkjac67k5+frmmuu0TnnnKPExERf23bO6ZFHHtH555+vjRs3asmSJZoxY0ZnDh9dZNeuXbr++utVVFRkYX7JJZcoGo1q7ty5mjlzpjIyMrp5lJ2v188U9nXqqadKkjZu3Cjp/69jbtiwQYWFherTp49+8YtfSNpzSeHuu+9WXl6egsGgBg8erOLiYu3YsSNmm8453XzzzTr00EOVlpamCRMm6MMPP2yx77a+U3jjjTdUWFiojIwMpaena8yYMbrnnntsfPfdd58kxVwOa9bZYzwQzz77rIqKipSdna3U1FTl5uZq7ty5ikQira7/1ltvady4cQqFQho+fLjuv//+Fus0NDSorKxMP/jBD5SamqohQ4bo2muvVUNDQ7vj2bBhgzZs2NChce/evVuXXXaZLQsEApo1a5Y2b96s119/vd1ttGXVqlXatGmTpk6dqqlTp+rVV1/V5s2bW6wXjUZ1zz336KijjlIwGFRmZqZOP/10rV692sZTV1enhx9+2M6B5u9Qpk+frmHDhrXY5u9+97uYc0WSFi5cqFNPPVWDBg1SamqqjjjiCFVUVPg+vo6orq7WOeeco6FDh9pr+Otf/1q7du1qdf1PPvlEBQUFSk9PV3Z2tubMmaN9mzl39LxvzWeffaZ169a1u15VVZW2b98ec15IUklJierq6vTCCy+0u43vo14/U9hX8w+JAQMG2LKmpiYVFBTo5JNP1u9//3ulpaVJkoqLi7Vo0SJddNFFKi0t1caNG7VgwQKtWbNGq1atUnJysiTpxhtv1M0336zCwkIVFhbq7bff1uTJk9XY2NjueF5++WWdccYZysrK0pVXXqmDDz5Ya9eu1V//+lddeeWVKi4u1tatW/Xyyy9r8eLFLerjMcaOWrRokcLhsH7zm98oHA7rlVde0Y033qhvvvlGd9xxR8y6O3bsUGFhoc4991ydd955euKJJzRr1iylpKToV7/6laQ9b/yzzjpLr732mmbOnKnRo0fr/fff11133aWPPvqo3Uspp512miRp06ZN+11vzZo1Sk9P1+jRo2OWH3fccfb4ySef7OGZ+H9LlixRbm6ujj32WB155JFKS0vTo48+qmuuuSZmvYsvvliLFi3SlClTNGPGDDU1Nam6ulr//Oc/dcwxx2jx4sWaMWOGjjvuOM2cOVOSlJub63k8FRUVysvL01lnnaWkpCQ9//zzuuyyyxSNRlVSUuLrGNuzdOlS7dy5U7NmzdKAAQP05ptvqry8XJs3b9bSpUtj1o1EIjr99NN1wgkn6Pbbb9eyZctUVlampqYmzZkzx9br6HnfmgsvvFD/+Mc/WgTNvtasWSNJdqWh2dixY5WQkKA1a9bol7/8pdeno+dzvdTChQudJLdixQr35Zdfus8//9w99thjbsCAAS4UCrnNmzc755ybNm2ak+R++9vfxtRXV1c7SW7JkiUxy5ctWxazfNu2bS4lJcUVFRW5aDRq61133XVOkps2bZotq6qqcpJcVVWVc865pqYmN3z4cJeTk+N27NgRs5+9t1VSUuJae6m6YoxtkeRKSkr2u87OnTtbLCsuLnZpaWmuvr7eluXn5ztJ7s4777RlDQ0N7uijj3aDBg1yjY2NzjnnFi9e7BISElx1dXXMNu+//34nya1atcqW5eTktDiOnJwcl5OT0+6xFRUVuREjRrRYXldX1+q50VGNjY1uwIAB7vrrr7dl559/vvvhD38Ys94rr7ziJLnS0tIW29j79UpPT2/1tZo2bVqrx1lWVtbivGntNSooKGhx/Pn5+S4/P7+Vo4qVk5PjioqK9rtOa/u87bbbXCAQcJ9++qkta34vXnHFFbYsGo26oqIil5KS4r788kvnXMfP+7aOo/n8a09JSYlLTExs9bHMzEw3derUdrfxfdTrLx9NnDhRmZmZGjJkiKZOnapwOKynn35ahxxySMx6s2bNivn30qVL1a9fP02aNEk1NTX2Z+zYsQqHw6qqqpIkrVixQo2NjbriiitipupXXXVVu2Nbs2aNNm7cqKuuukoHHXRQzGP7TvtbE48xehEKhezv3377rWpqavSTn/xEO3fubDFdT0pKUnFxsf07JSVFxcXF2rZtm9566y07vtGjR2vUqFExx9d8CbD5+NqyadOmdmcJ0p5rx6mpqS2WN3//09Zljva89NJL2r59e8x3V+edd57efffdmEt3Tz75pAKBgMrKylpsoyPngRd7v0a1tbWqqalRfn6+PvnkE9XW1nbqvlrbZ11dnWpqajRu3Dg55+zT+N72vsut+a63xsZGrVixQlLHz/u2rFy5st1ZgrTndU9JSWn1sWAw6Pu86Ol6/eWj++67TyNHjlRSUpIGDx6sww8/XAkJsVmYlJSkQw89NGbZ+vXrVVtbq0GDBrW63W3btkmSPv30U0nSYYcdFvN4ZmZmu19CNV/K8nvPfjzG6MWHH36oG264Qa+88oq++eabmMf2/YGTnZ3d4sv8kSNHStrzw/yEE07Q+vXrtXbtWmVmZra6v+bjO1ChUKjV7yjq6+vtcT8qKys1fPhwpaam6uOPP5a055JPWlqalixZoltvvVXSnvMgOztb/fv393kEHbdq1SqVlZXp9ddfb3EHXm1trfr169fp+/zss89044036rnnnmtxzX/f8yIhIUEjRoyIWbb3eSF1/Lw/UKFQqM3Lq/X19b7Pi56u14fCcccd1+Ka4L5SU1NbBEU0GtWgQYO0ZMmSVmva+kEVTz1pjF9//bXy8/PVt29fzZkzR7m5uQoGg3r77bc1e/ZsRaNRz9uMRqM66qijNH/+/FYfHzJkyIEOW5KUlZWlqqoqOediPpl/8cUXkvYEmFfffPONnn/+edXX17cIY0l65JFHdMstt3TKTKCtbez7Bf+GDRt02mmnadSoUZo/f76GDBmilJQUvfjii7rrrrt8vUbtiUQimjRpkr766ivNnj1bo0aNUnp6urZs2aLp06f7Pi/icd5nZWUpEolo27ZtMQHU2Nio7du3+zovvg96fSj4lZubqxUrVuikk07a7yeCnJwcSXs+vez9CefLL79s906I5i8KP/jgA02cOLHN9dp608djjB21cuVKbd++XU899VTM72E03+W1r61bt7a49fejjz6SJLuTJjc3V++++65OO+20Tr+Msrejjz5af/zjH7V27VodccQRtvyNN96wx7166qmnVF9fr4qKCg0cODDmsf/85z+64YYbtGrVKp188snKzc3V8uXL9dVXX+13ttDWc5CRkdHqL8U1zxCbPf/882poaNBzzz2noUOH2vL2LrcciPfff18fffSRHn74YV144YW2/OWXX251/Wg0qk8++cRmB1Lr50VHzvsD1fy6r169WoWFhbZ89erVikajvs6L74Ne/52CX+eee64ikYjmzp3b4rGmpiZ7E06cOFHJyckqLy+PuU559913t7uPH//4xxo+fLjuvvvuFm/qvbfV/INz33XiMcaOar6Pf+/tNzY26g9/+EOr6zc1NemBBx6IWfeBBx5QZmamxo4dK2nP8W3ZskUPPfRQi/pdu3aprq5uv2Pq6C2pP/3pT5WcnBwzVuec7r//fh1yyCEaN25cu9vYV2VlpUaMGKFLL71UZ599dsyfq6++WuFw2D7p/vznP5dzrtVfUNz3PGjth39ubq5qa2v13nvv2bIvvvhCTz/9dMx6rb1GtbW1Wrhwoefj66jW9umcs1uuW9P8uyLN6y5YsEDJycl2N1lHz/u2dPSW1FNPPVX9+/dvcctuRUWF0tLSVFRU1O42vo+YKbQhPz9fxcXFuu222/TOO+9o8uTJSk5O1vr167V06VLdc889Ovvss5WZmamrr75at912m8444wwVFhZqzZo1eumll1p8QtxXQkKCKioqdOaZZ+roo4/WRRddpKysLK1bt04ffvihli9fLkn2Q7K0tFQFBQVKTEzU1KlT4zLGva1evVo333xzi+Xjx4/XuHHjlJGRoWnTpqm0tFSBQECLFy9u8wu97OxszZs3T5s2bdLIkSP1+OOP65133tGDDz5otxNecMEFeuKJJ3TppZeqqqpKJ510kiKRiNatW6cnnnhCy5cv3++lwY7eknrooYfqqquu0h133KHdu3fr2GOP1TPPPKPq6motWbIk5hfXmm+DXLhwYZu9lrZu3aqqqiqVlpa2+nhqaqoKCgq0dOlS3XvvvZowYYIuuOAC3XvvvVq/fr1OP/10RaNRVVdXa8KECfbF69ixY7VixQrNnz9f2dnZGj58uI4//nhNnTpVs2fP1s9+9jOVlpZq586dqqio0MiRI/X222/bfidPnqyUlBSdeeaZKi4u1nfffaeHHnpIgwYNsktlfnz88cetnhc/+tGPNHnyZOXm5urqq6/Wli1b1LdvXz355JNtzlCDwaCWLVumadOm6fjjj9dLL72kF154Qdddd51dFuroed+Wjt6SGgqFNHfuXJWUlOicc85RQUGBqqurVVlZqVtuuSUu3wF1i/jf8BQfzbek/utf/9rvetOmTXPp6eltPv7ggw+6sWPHulAo5Pr06eOOOuood+2117qtW7faOpFIxN10000uKyvLhUIhN378ePfBBx+0uE1y31tSm7322mtu0qRJrk+fPi49Pd2NGTPGlZeX2+NNTU3uiiuucJmZmS4QCLS4na4zx9gWSW3+mTt3rnPOuVWrVrkTTjjBhUIhl52d7a699lq3fPnyFsecn5/v8vLy3OrVq92JJ57ogsGgy8nJcQsWLGix38bGRjdv3jyXl5fnUlNTXUZGhhs7dqy76aabXG1tra13ILekNj8/t956q8vJyXEpKSkuLy/PVVZWtlivvLzcSXLLli1rc1t33nmnk+T+/ve/t7nOokWLnCT37LPPOuf2vMZ33HGHGzVqlEtJSXGZmZluypQp7q233rKadevWuVNOOcWFQqEWtxL/7W9/c0ceeaRLSUlxhx9+uKusrGz1ltTnnnvOjRkzxgWDQTds2DA3b9489+c//9lJchs3brT1vNyS2tZ5cfHFFzvnnPv3v//tJk6c6MLhsBs4cKC75JJL3LvvvuskuYULF9q2mt+LGzZscJMnT3ZpaWlu8ODBrqyszEUikRb77sh5fyC3pO69n8MPP9ylpKS43Nxcd9ddd8XcKtzbBJzrwL1ZACTtuXSxadMmvfnmm909FKBLcPkI6CDnnFauXKnKysruHgrQZZgpAAAMdx8BAAyhAAAwhAIAwBAKAADT4buPurLNALrXlClTPNdMnjzZc82rr77quUaSli1b5rnGTwdLP//bXlZWluea/Px8zzWSVFBQ4LnmySef9Fzz+OOPe67B90NH7itipgAAMIQCAMAQCgAAQygAAAyhAAAwhAIAwBAKAABDKAAADKEAADCEAgDAEAoAAEMoAABMh//nNRrixVdCgr+8jkQinmu+++47zzVJSd7/J1e//8lfKBTyVedVfX2955pgMOi55ttvv/VcI0m7d+/2XJOYmOi5pl+/fp5r+Pnw/UBDPACAJ4QCAMAQCgAAQygAAAyhAAAwhAIAwBAKAABDKAAADKEAADCEAgDAEAoAAEMoAACM965miItoNOqr7rPPPvNck5qa6rnGT3M7vw3x/DSQ2759u+ea+fPne66ZOXOm55phw4Z5rpH8PQ/Jycmeaz7//HPPNeg9mCkAAAyhAAAwhAIAwBAKAABDKAAADKEAADCEAgDAEAoAAEMoAAAMoQAAMIQCAMAQCgAAQygAAAxdUnuZnTt3eq4Jh8Oea5qamjzXBAIBzzWSlJDg/bPLQQcd5Lnmsssu81wzYMAAzzV+jkfy1/E0MTHRc019fb3nGvQezBQAAIZQAAAYQgEAYAgFAIAhFAAAhlAAABhCAQBgCAUAgCEUAACGUAAAGEIBAGAIBQCACTjnXIdW9NnMDPHVwZczxo4dOzzXRCIRzzV+RaNRzzVJSd57PfppONfQ0OC5prGx0XON5O896Od16tevn+eavn37eq5B/HXk5wMzBQCAIRQAAIZQAAAYQgEAYAgFAIAhFAAAhlAAABhCAQBgCAUAgCEUAACGUAAAGEIBAGC8dw1Dr9PTmx36GV9TU5PnGr+N6rzy06xP8tfczk9NKBTyXIPeg5kCAMAQCgAAQygAAAyhAAAwhAIAwBAKAABDKAAADKEAADCEAgDAEAoAAEMoAAAMoQAAMDTEg6+maX6a1EWjUc81fiUkeP+8k5iY6LnGOee5Jp7Pgx9+G/ahd2CmAAAwhAIAwBAKAABDKAAADKEAADCEAgDAEAoAAEMoAAAMoQAAMIQCAMAQCgAAQygAAAydr3qoIUOGdPcQ9qunN4Lz07DPT008+XnO4+Xggw/2XPPf//63C0aCA8VMAQBgCAUAgCEUAACGUAAAGEIBAGAIBQCAIRQAAIZQAAAYQgEAYAgFAIAhFAAAhlAAABhCAQBg6JLaQx1yyCG+6hoaGjp5JK2LRCKea+LZ5dNPR9aEBO+fkRITEz3X+Hnu/NY1NTX52pdXAwcO9FxDl9SeiZkCAMAQCgAAQygAAAyhAAAwhAIAwBAKAABDKAAADKEAADCEAgDAEAoAAEMoAAAMoQAAMDTE66GysrJ81flpOuenEVxSkvdTx29zNj/HFAgEfO3LKz+N9/yOLV7H5MfgwYM913zwwQddMBIcKGYKAABDKAAADKEAADCEAgDAEAoAAEMoAAAMoQAAMIQCAMAQCgAAQygAAAyhAAAwhAIAwNAQr4eqq6vzVeen6Zyfpm6JiYmeayKRiOcayV8jOD9N9Pzw89z55ec5j1cTvWAwGJf9oOsxUwAAGEIBAGAIBQCAIRQAAIZQAAAYQgEAYAgFAIAhFAAAhlAAABhCAQBgCAUAgCEUAACGhng91HvvveerLhwOe67ZtWuX55rk5GTPNQkJ8fsM4qdRnZ8mevGqkfwdU7wa9tXU1MRlP+h6zBQAAIZQAAAYQgEAYAgFAIAhFAAAhlAAABhCAQBgCAUAgCEUAACGUAAAGEIBAGAIBQCAIRQAACbgOtiyMRAIdPVY0An8dOD8+uuv47KfSCTiuUbyd+752Vc8jyle6uvrPdeMGDHCc01iYqLnmnh1cMX/68g5zkwBAGAIBQCAIRQAAIZQAAAYQgEAYAgFAIAhFAAAhlAAABhCAQBgCAUAgCEUAACGUAAAmKTuHgC6n59mZrt37/Zc46fhnCQlJHj/7OJ3X175adbnd2x+9pWU5P0t7md8NLfrPZgpAAAMoQAAMIQCAMAQCgAAQygAAAyhAAAwhAIAwBAKAABDKAAADKEAADCEAgDAEAoAAENDPPhqgBavhnPx3Fe8nge/zeOSk5M91/hpJtjU1OS5Br0HMwUAgCEUAACGUAAAGEIBAGAIBQCAIRQAAIZQAAAYQgEAYAgFAIAhFAAAhlAAABhCAQBgaIjXQ4XD4e4eQqfz05xNkgKBQFxq/DS383tMfvg5pqQk72/xeDXe89sYEF2LmQIAwBAKAABDKAAADKEAADCEAgDAEAoAAEMoAAAMoQAAMIQCAMAQCgAAQygAAAyhAAAwNMTroTIyMuK2Lz+N4Pw0Z/Mrnvvyyk8jOD/Pd0/Xv39/zzU1NTVdMBIcKGYKAABDKAAADKEAADCEAgDAEAoAAEMoAAAMoQAAMIQCAMAQCgAAQygAAAyhAAAwhAIAwBAKAABDl9Qeqm/fvnHbl58upHRJ3cNPx9N4dkmNRqNx2U84HPZcQ5fUnomZAgDAEAoAAEMoAAAMoQAAMIQCAMAQCgAAQygAAAyhAAAwhAIAwBAKAABDKAAADKEAADA0xOuhMjIy4raveDZo8yNeDfv8PA/xbCbopy5eDfGGDh3quWbTpk2dPxAcMGYKAABDKAAADKEAADCEAgDAEAoAAEMoAAAMoQAAMIQCAMAQCgAAQygAAAyhAAAwhAIAwNAQr4fq169fdw9hv/w0j0tI8PcZhIZ4B1YXD1lZWd09BHQSZgoAAEMoAAAMoQAAMIQCAMAQCgAAQygAAAyhAAAwhAIAwBAKAABDKAAADKEAADCEAgDA0BCvhwqHw3HbV7yauvX0RnB+9uOnyV80GvVcI/lr2BcvGRkZ3T0EdBJmCgAAQygAAAyhAAAwhAIAwBAKAABDKAAADKEAADCEAgDAEAoAAEMoAAAMoQAAMIQCAMDQEK+H6tu3b3cPodPFq7FdPPlpiJeYmOhrX34a6fndl1d9+vSJy37Q9ZgpAAAMoQAAMIQCAMAQCgAAQygAAAyhAAAwhAIAwBAKAABDKAAADKEAADCEAgDAEAoAAEMoAAAMXVJ7qPT09Ljta/fu3Z5r/HQH7eldUuM1vuTkZF91DQ0NnmvidUzxPF/RtZgpAAAMoQAAMIQCAMAQCgAAQygAAAyhAAAwhAIAwBAKAABDKAAADKEAADCEAgDAEAoAAENDvB4qGAx29xD2K54N8aLRqK86r/yMzznnucbPc+dXvJ67/v37x2U/6HrMFAAAhlAAABhCAQBgCAUAgCEUAACGUAAAGEIBAGAIBQCAIRQAAIZQAAAYQgEAYAgFAIChIV4PNXDgwLjtKynJ+2mQnJzcBSNpnZ+mbn6azsWruZ3fhnh+Gvb52ddXX33luSYzM9NzDXomZgoAAEMoAAAMoQAAMIQCAMAQCgAAQygAAAyhAAAwhAIAwBAKAABDKAAADKEAADCEAgDA0BCvh8rLy/NV19TU5LnGTyO4xsbGuNRI/pq6+Xke/IwvGAx6rolEIp5rJH+vk5/nwU+zw5EjR3quQc/ETAEAYAgFAIAhFAAAhlAAABhCAQBgCAUAgCEUAACGUAAAGEIBAGAIBQCAIRQAAIZQAAAYQgEAYOiS2kPV1NT4qktK8v6ShsPhuOwHB8ZPx9Pdu3d7rgmFQp5rysrKPNegZ2KmAAAwhAIAwBAKAABDKAAADKEAADCEAgDAEAoAAEMoAAAMoQAAMIQCAMAQCgAAQygAAEzAOec6tGIg0NVjQSeYMGGC55rc3FzPNUOGDPFc46fRmiT169fPc01aWprnmg6+FWJEo1HPNX4a20nSF1984blm69atnmseeeQRzzW1tbWeaxB/HTnHmSkAAAyhAAAwhAIAwBAKAABDKAAADKEAADCEAgDAEAoAAEMoAAAMoQAAMIQCAMAQCgAA0+GGeACA3o+ZAgDAEAoAAEMoAAAMoQAAMIQCAMAQCgAAQygAAAyhAAAwhAIAwPwfrseM1FeMHCEAAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "image_index = 27\n",
        "test_image, test_label = test_dataset[image_index]\n",
        "\n",
        "with torch.no_grad():\n",
        "    model.eval()\n",
        "    output = model(test_image.unsqueeze(0))\n",
        "    _, predicted_label = torch.max(output, 1)\n",
        "\n",
        "test_image_numpy = test_image.squeeze().numpy()\n",
        "\n",
        "plt.imshow(test_image_numpy, cmap='gray')\n",
        "plt.title(f'Predicted Label: {predicted_label.item()}, Actual Label: {test_label}')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FoypxOXgGjuC"
      },
      "source": [
        "Notes for Part 1\n",
        "\n",
        "1. Activation fucntion:\n",
        "\n",
        "class Net(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = torch.nn.Linear(28*28, 128)\n",
        "        self.fc2 = torch.nn.Linear(128, 64)\n",
        "        self.fc3 = torch.nn.Linear(64, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28*28)\n",
        "        x = torch.relu(self.fc1(x))  # Change activation function here\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "2. loss function and optimizer\n",
        "\n",
        "model = Net()\n",
        "criterion = torch.nn.CrossEntropyLoss()  # Change loss function\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "3. ~adding a dropout layer\n",
        "\n",
        "class Net(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = torch.nn.Linear(28*28, 128)\n",
        "        self.dropout = torch.nn.Dropout(0.2)  # Add a Dropout layer here\n",
        "        self.fc2 = torch.nn.Linear(128, 64)\n",
        "        self.fc3 = torch.nn.Linear(64, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28*28)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.dropout(x)  # Apply Dropout\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "4. model configurations / epochs\n",
        "\n",
        "epochs = 10  # Change number of epochs\n",
        "for epoch in range(epochs):\n",
        "    # Training loop\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        # Training steps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5nxrEoAHAUX"
      },
      "source": [
        "## CNN Implimentation with Keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ccRJi8VXH3_O"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras.datasets import fashion_mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten\n",
        "from keras.optimizers import SGD\n",
        "from keras.utils import to_categorical\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k41uN-aAIH6Y"
      },
      "outputs": [],
      "source": [
        "# Mapping the labels for the MNIST dataset\n",
        "labels_map = {\n",
        "    0: \"0\", 1: \"1\", 2: \"2\", 3: \"3\", 4: \"4\",\n",
        "    5: \"5\", 6: \"6\", 7: \"7\", 8: \"8\", 9: \"9\"\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4_MUVyZ5Iksr"
      },
      "outputs": [],
      "source": [
        "# Load and preprocess the data\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AEoqWEFz5Ms-"
      },
      "outputs": [],
      "source": [
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "# Preprocess the data\n",
        "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1).astype('float32') / 255\n",
        "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1).astype('float32') / 255\n",
        "\n",
        "# Convert labels to one-hot encoding\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eX_tkHuwEK7B"
      },
      "outputs": [],
      "source": [
        "model = Sequential([\n",
        "    Flatten(input_shape=(28, 28)),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7l92S_RxJZTm"
      },
      "outputs": [],
      "source": [
        "def create_model(num_layers=2, units_per_layer=128, activation='relu'):\n",
        "    model = Sequential()\n",
        "    model.add(Flatten(input_shape=(28, 28)))\n",
        "\n",
        "    for _ in range(num_layers):\n",
        "        model.add(Dense(units_per_layer, activation=activation))\n",
        "\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nPfHtKytJd9Q"
      },
      "outputs": [],
      "source": [
        "num_layers = 6\n",
        "units_per_layer = 256\n",
        "activation = 'relu'\n",
        "learning_rate = 0.01\n",
        "epochs = 75\n",
        "batch_size = 48\n",
        "\n",
        "# Create the model\n",
        "model = create_model(num_layers=num_layers, units_per_layer=units_per_layer, activation=activation)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=SGD(learning_rate=learning_rate),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JlPkc9auJkET"
      },
      "outputs": [],
      "source": [
        "model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1)\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(x_test, y_test)\n",
        "print('Test accuracy:', accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ig5GXhcG5fy6"
      },
      "outputs": [],
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "# Define early stopping callback\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=True)\n",
        "\n",
        "# Train the model with early stopping\n",
        "model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, validation_split=0.2, callbacks=[early_stopping])\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(x_test, y_test)\n",
        "print('Test accuracy:', accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zJa4Lf76KZDM"
      },
      "outputs": [],
      "source": [
        "image_index = 27\n",
        "\n",
        "# Extract the test image and label\n",
        "test_image = x_test[image_index]\n",
        "test_label = np.argmax(y_test[image_index])\n",
        "\n",
        "# Reshape the test image for prediction (Keras expects a batch dimension)\n",
        "test_image_reshaped = np.expand_dims(test_image, axis=0)\n",
        "\n",
        "# Make predictions on the test image\n",
        "predicted_label = np.argmax(model.predict(test_image_reshaped), axis=-1)\n",
        "\n",
        "# Plot the test image with predicted and actual labels\n",
        "plt.imshow(test_image, cmap='gray')\n",
        "plt.title(f'Predicted Label: {predicted_label[0]}, Actual Label: {test_label}')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cc8F7Lo_AOII"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# Load the Fashion MNIST dataset\n",
        "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "\n",
        "# Normalize pixel values to be between 0 and 1\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
        "\n",
        "# Define the CNN model\n",
        "model = models.Sequential([\n",
        "    layers.Conv2D(16, (5, 5), activation='sigmoid', input_shape=(28, 28, 1)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(32, (3, 3), activation='tanh'),\n",
        "    layers.MaxPooling2D((3, 3)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128, activation='softmax'),\n",
        "    layers.Dense(10)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='SGD',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(train_images.reshape(-1, 28, 28, 1), train_labels, epochs=25)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(test_images.reshape(-1, 28, 28, 1), test_labels, verbose=2)\n",
        "print('\\nTest accuracy:', test_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nK1xXT5W7cMS"
      },
      "source": [
        "## AUTOMATED TUNING (EXETENDED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yIeVei_C8sVB"
      },
      "outputs": [],
      "source": [
        "https://www.tensorflow.org/tensorboard/hyperparameter_tuning_with_hparams"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
